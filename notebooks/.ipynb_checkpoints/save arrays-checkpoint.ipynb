{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76b0d8c-8e9a-46ef-8b1c-2a5cb2d95d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "wd = os.getcwd()\n",
    "wd = (wd[:-10]+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd413e71-3da1-4444-8c6f-1d0bcb4096f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_sc_files = sorted(glob.glob(wd+'/data/BD/sc/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in bd_sc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "bd_sc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3ccf579-a9ed-44fb-8d63-d7bfd9b2cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_fbc_files = sorted(glob.glob(wd+'/data/BD/fbc/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in bd_fbc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "bd_fbc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7399b7c7-e037-4ac9-8a55-8e4d1b51cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_fa_files = sorted(glob.glob(wd+'/data/BD/fa/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in bd_fa_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "bd_fa_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0db2bf6-5bdc-4cdd-9723-04943a98e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_sl_files = sorted(glob.glob(wd+'/data/BD/sl/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in bd_sl_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "bd_sl_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fb1f61e-6e71-4c07-85a9-1680fd92f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_fc_files = sorted(glob.glob(wd+'/data/BD/func/*-cor.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in bd_fc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "bd_fc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c24caf6-b15d-44ae-a9f9-f9e157eea633",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_pfc_files = sorted(glob.glob(wd+'/data/BD/func/*-pcor.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in bd_pfc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "bd_pfc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d46cd8a1-97cc-4b94-824b-2457f48ce54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_sc_files = sorted(glob.glob(wd+'/data/HC/sc/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in hc_sc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "hc_sc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced9cc72-1d3e-479f-90ec-b48b57ffe715",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_fbc_files = sorted(glob.glob(wd+'/data/HC/fbc/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in hc_fbc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "hc_fbc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a6da49-fd89-4588-8da4-496dd69853a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_fa_files = sorted(glob.glob(wd+'/data/HC/fa/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in hc_fa_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "hc_fa_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fa0dd47-e7d8-4fd3-b3e4-eb2f8b8dea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_sl_files = sorted(glob.glob(wd+'/data/HC/sl/*.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in hc_sl_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "hc_sl_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9390c378-7773-41ae-836c-e1fc70fbd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_fc_files = sorted(glob.glob(wd+'/data/HC/func/*-cor.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in hc_fc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "hc_fc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cdbaa22-849e-4f6e-a34b-53762ec6223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_pfc_files = sorted(glob.glob(wd+'/data/HC/func/*-pcor.csv'))\n",
    "data_list = []\n",
    "# Load data from each CSV file and add it to the list\n",
    "for file in hc_pfc_files:\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate the list of arrays along a new axis to create a 3D numpy array\n",
    "hc_pfc_mats = np.stack(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e71ca25-29e3-4d67-a448-326eb0f60dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.10127217,  0.00237348, ...,  0.02533813,\n",
       "         0.02783002,  0.02843922],\n",
       "       [ 0.10127217,  1.        ,  0.12537723, ..., -0.0215113 ,\n",
       "        -0.04559335, -0.0072075 ],\n",
       "       [ 0.00237348,  0.12537723,  1.        , ..., -0.04269359,\n",
       "        -0.01681994, -0.0123962 ],\n",
       "       ...,\n",
       "       [ 0.02533813, -0.0215113 , -0.04269359, ...,  1.        ,\n",
       "        -0.0364095 ,  0.04924952],\n",
       "       [ 0.02783002, -0.04559335, -0.01681994, ..., -0.0364095 ,\n",
       "         1.        , -0.02189837],\n",
       "       [ 0.02843922, -0.0072075 , -0.0123962 , ...,  0.04924952,\n",
       "        -0.02189837,  1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_pfc_mats[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55e88e66-f2f8-4dde-bcd9-5ab5955fb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "euc = np.genfromtxt(wd+'/data/euc.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85b97e84-c969-48b2-8462-8c7d69243790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all as npy (add the mats needed)\n",
    "np.save(wd+'/data/npy/hc_sc_mats.npy', hc_sc_mats)\n",
    "np.save(wd+'/data/npy/bd_sc_mats.npy', bd_sc_mats)\n",
    "np.save(wd+'/data/npy/bd_fbc_mats.npy', bd_fbc_mats)\n",
    "np.save('/home/shir/Documents/connectomics/sch200_tian1/npy/euc.npy', euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a4267fd-46f3-43e9-9921-27b036f387bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = np.load(wd+'/data/npy/bd_pfc_mats.npy')\n",
    "hm.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
